export interface ReportSection {
  id: string;
  title: string;
  subtitle: string;
  color: string;
  position: [number, number, number];
  content: {
    heading: string;
    paragraphs: string[];
  };
}

export const reportSections: ReportSection[] = [
  {
    id: "introduction",
    title: "Introduction",
    subtitle: "The projectets background and aim",
    color: "#E8A838",
    position: [0, 0, 0],
    content: {
      heading: "Introduction",
      paragraphs: [
        "This report compares two distinct approaches to movie recommendation systems: a traditional Machine Learning (ML) approach using TF-IDF (Term Frequency-Inverse Document Frequency) and a modern Large Language Model (LLM) approach. The objective is to evaluate how well these two methodologies align when giving their movie recommendations based of the user requests.",
      ],
    },
  },
  {
    id: "setup",
    title: "Setup",
    subtitle: "Preparation of dataset & system architecture",
    color: "#A855F7",
    position: [6, -2, -12],
    content: {
      heading: "Setup",
      paragraphs: [
        "Dataset: The study utilized the IMDB Top 1000 Movies dataset to provide a constrained and testable environment.",
        "Data Preprocessing: Features such as Series title, Genre, Director, Stars 1-4 and Overview were used, while others like Gross and Certificate were dropped for the comparison.",
        "System Architecture: A Next.JS frontend was developed to allow users to toggle between the ML and LLM models, as well as insert user requests. The backend, powered by Python (Main.py), handled the data retrieval and processing.",
      ],
    },
  },
  {
    id: "method",
    title: "Method",
    subtitle: "Model implementation",
    color: "#3B82F6",
    position: [8, 2, -5],
    content: {
      heading: "Method",
      paragraphs: [
        "The study implemented two separate recommendation models:",
        "Model 1: ML (TF-IDF)",
        "This model vectorizes the movie dataset and user input using TF-IDF. Recommendations are generated by performing a Cosine Similarity calculation between the vectorized user input and the movie data. This method focuses on term frequency and importance within the documents.",
        "Model 2: LLM API",
        "This model utilizes the Gemini 2.5 Flash API. It employs structured prompting, where the LLM is instructed to act as a 'strict data retrieval assistant'. The model receives the stripped dataset and the user request, then returns a raw JSON list of the top 10 movies sorted by relevance.",
        "Test phase:",
        "First Ten specific user inputs were crafted to target a single, identifiable movie from the dataset. An example of such an input describes the plot of Titanic in detail:",
        "'I want to see a movie about a poor young boy that falls in love with a upper-class girl on a ship. The ship later hits an iceberg and sinks.'.",
        "In addition to targeted tests, more 'loosely' defined searches were conducted, such as requesting a specific genre e.g., 'a animated movie about animals'.",
        "To determine how well the two approaches 'agreed', the system compared the 10 recommendations generated by each model for every input."
      ],
    },
  },
  {
    id: "results",
    title: "Result",
    subtitle: "Results based on test phase",
    color: "#10B981",
    position: [-7, -1, -8],
    content: {
      heading: "Result",
      paragraphs: [
        "Each models 10 movie recommendations were analyzed for accuracy and cross-model agreement.",
        "1. Specific Targeted Searches:",
        "In this phase, 10 distinct user inputs were designed to describe the plot of a specific movie within the IMDB Top 1000 dataset to see if the models could identify the intended film.",
        "The Gemini 2.5 Flash model demonstrated high precision, identifying the desired movie and placing it in the first-place position 9 out of 10 times.",
        "The TF-IDF model was less effective, placing the desired movie in its top 10 results 5 out of 10 times, with only 3 instances appearing in the first-place spot.",
        "When comparing the full lists of 10 recommendations for these 10 specific searches (100 total recommendations per model), the models recommended the exact same movie only 12 times (12%). For one specific input, neither the ML nor the LLM model was able to retrieve the desired movie.",
        "2. Loose and Generic Searches:",
        "The generic searches did not yield higher accuracy or better results than the specific targeted queries for either model.",
      ],
    },
  },
  {
    id: "conclusion & discussion",
    title: "Conclusion & Discussion",
    subtitle: "Summary and discussion of result",
    color: "#EAB308",
    position: [-5, 3, -15],
    content: {
      heading: "Conclusion & Discussion",
      paragraphs: [
        "The study concludes that ML and LLM models do not align well in their recommendations.",
        "The TF-IDF model is limited by strict keyword matching; it cannot recognize synonyms e.g., matching 'funny' to 'hilarious'. Furthermore the LLM excels at Semantic Search, understanding context and synonyms. It can also leverage its pre-existing 'knowledge' to better understand movie plots beyond the provided dataset.",
        "Future Improvements:",
        "To enhance the ML model a more in-depth plot summary could be used as well as adding a synonym library, additionally implementing word unscrambling e.g. 'vimoe' gets rearranged to 'movie', could prove beneficial for the model.",
      ],
    },
  },
];
